{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1h_-QNx_hiDuEREZRvYGkwRkCZUtCYq1p","authorship_tag":"ABX9TyMdYYXoSDAMMsPFmwpXnjyq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Xr5E60m3InC","executionInfo":{"status":"ok","timestamp":1632741061892,"user_tz":-540,"elapsed":7534,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"4a56c201-836b-4526-d04d-84e41edd47ff"},"source":["!git clone https://github.com/ultralytics/yolov3\n","!cd yolov3;pip install -qr requirements.txt"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov3'...\n","remote: Enumerating objects: 9862, done.\u001b[K\n","remote: Total 9862 (delta 0), reused 0 (delta 0), pack-reused 9862\u001b[K\n","Receiving objects: 100% (9862/9862), 9.19 MiB | 16.51 MiB/s, done.\n","Resolving deltas: 100% (6667/6667), done.\n","\u001b[K     |████████████████████████████████| 636 kB 11.9 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OFoRNcsyDcF-","executionInfo":{"status":"ok","timestamp":1632741076987,"user_tz":-540,"elapsed":11439,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"dbd92b47-82ae-423f-897e-64e82a195a04"},"source":["!wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n","!wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-09-27 11:12:19--  https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n","Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n","Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 791918971 (755M) [application/x-gzip]\n","Saving to: ‘images.tar.gz’\n","\n","images.tar.gz       100%[===================>] 755.23M  69.7MB/s    in 11s     \n","\n","2021-09-27 11:12:29 (70.4 MB/s) - ‘images.tar.gz’ saved [791918971/791918971]\n","\n","--2021-09-27 11:12:29--  https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n","Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n","Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19173078 (18M) [application/x-gzip]\n","Saving to: ‘annotations.tar.gz’\n","\n","annotations.tar.gz  100%[===================>]  18.28M  59.7MB/s    in 0.3s    \n","\n","2021-09-27 11:12:30 (59.7 MB/s) - ‘annotations.tar.gz’ saved [19173078/19173078]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"EFu1FG9ADfCk"},"source":["!mkdir /content/data\n","!tar -xvf images.tar.gz -C /content/data\n","!tar -xvf annotations.tar.gz -C /content/data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YozT4BUHEySF","executionInfo":{"status":"ok","timestamp":1632741096627,"user_tz":-540,"elapsed":501,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}}},"source":["!mkdir /content/ox_pet;\n","!cd /content/ox_pet; mkdir images; mkdir labels;\n","!cd /content/ox_pet/images; mkdir train; mkdir val;\n","!cd /content/ox_pet/labels; mkdir train; mkdir val;"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"PTlT-gpIFUs2","executionInfo":{"status":"ok","timestamp":1632741100855,"user_tz":-540,"elapsed":1196,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}}},"source":["import pandas as pd\n","import os\n","from sklearn.model_selection import train_test_split\n","\n","def make_train_valid_df(list_filepath, img_dir, anno_dir, test_size=0.1):\n","    pet_df = pd.read_csv(list_filepath, sep=' ', header=None, names=['img_name', 'class_id', 'etc1', 'etc2'])\n","    \n","    #pet_df에서 class name과 img_filepath, anno_filepath를 만든 다음에 train_test_split으로 나누고 없는거 검사해서 지운다\n","    pet_df['class_name'] = pet_df['img_name'].apply(lambda x:x[:x.rfind('_')])\n","    pet_df['img_filepath'] = img_dir + pet_df['img_name'] + '.jpg'\n","    pet_df['anno_filepath'] = anno_dir + pet_df['img_name'] + '.xml'\n","    pet_df = remove_no_annos(pet_df)\n","\n","    train_df, val_df = train_test_split(pet_df, test_size=test_size, stratify=pet_df['class_id'], random_state=2021)\n","    return pet_df, train_df, val_df\n","\n","\n","def remove_no_annos(df):\n","    remove_rows = []\n","\n","    for index, row in df.iterrows():\n","        anno_filepath = row['anno_filepath']\n","        if not os.path.exists(anno_filepath):\n","            print('index:', index, anno_filepath, '가 존재하지 않아서 삭제합니다.')\n","            remove_rows.append(index)\n","    df = df.drop(remove_rows, axis=0, inplace=False)\n","    return df"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JqQaFVUfGUT2","executionInfo":{"status":"ok","timestamp":1632741103741,"user_tz":-540,"elapsed":783,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"774d1628-3345-4fd1-822b-f6ad3ada09d5"},"source":["pet_df, train_df, val_df = make_train_valid_df('/content/data/annotations/trainval.txt', \n","                                               '/content/data/images/', '/content/data/annotations/xmls/', test_size=0.1)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["index: 4 /content/data/annotations/xmls/Abyssinian_104.xml 가 존재하지 않아서 삭제합니다.\n","index: 262 /content/data/annotations/xmls/Bengal_111.xml 가 존재하지 않아서 삭제합니다.\n","index: 1456 /content/data/annotations/xmls/samoyed_10.xml 가 존재하지 않아서 삭제합니다.\n","index: 2128 /content/data/annotations/xmls/Bengal_175.xml 가 존재하지 않아서 삭제합니다.\n","index: 2395 /content/data/annotations/xmls/Egyptian_Mau_14.xml 가 존재하지 않아서 삭제합니다.\n","index: 2402 /content/data/annotations/xmls/Egyptian_Mau_156.xml 가 존재하지 않아서 삭제합니다.\n","index: 2427 /content/data/annotations/xmls/Egyptian_Mau_186.xml 가 존재하지 않아서 삭제합니다.\n","index: 3177 /content/data/annotations/xmls/Ragdoll_199.xml 가 존재하지 않아서 삭제합니다.\n","index: 3246 /content/data/annotations/xmls/saint_bernard_15.xml 가 존재하지 않아서 삭제합니다.\n"]}]},{"cell_type":"code","metadata":{"id":"Z_YOQn70GZKc"},"source":["CLASS_NAME = pet_df['class_name'].unique().tolist()\n","CLASS_NAME"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lT8xKOJOLq2k","executionInfo":{"status":"ok","timestamp":1632741110813,"user_tz":-540,"elapsed":4,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}}},"source":["import glob\n","import xml.etree.ElementTree as ET\n","\n","def xml_to_txt(input_xml_file, output_txt_file, object_name):\n","    tree = ET.parse(input_xml_file)\n","    root = tree.getroot()\n","    img_node = root.find('size')\n","\n","    if img_node is None:\n","        return None\n","    \n","    img_width = int(img_node.find('width').text)\n","    img_height = int(img_node.find('height').text)\n","\n","    with open(output_txt_file, 'w') as output_fpointer:\n","        for obj in root.findall('object'):\n","            xmlbox = obj.find('bndbox')\n","            x1 = int(xmlbox.find('xmin').text)\n","            y1 = int(xmlbox.find('ymin').text)\n","            x2 = int(xmlbox.find('xmax').text)\n","            y2 = int(xmlbox.find('ymax').text)\n","            if (x1 < 0) or (x2 < 0) or (y1 < 0) or (y2 < 0):\n","                break\n","            \n","            class_id, cx_norm, cy_norm, w_norm, h_norm = convert_yolo_coord(object_name, img_width, img_height, x1, y1, x2, y2)\n","\n","            value_str = ('{0} {1} {2} {3} {4}').format(class_id, cx_norm, cy_norm, w_norm, h_norm)\n","            output_fpointer.write(value_str+'\\n')\n","\n","def convert_yolo_coord(object_name, img_width, img_height, x1, y1, x2, y2):\n","    class_id = CLASS_NAME.index(object_name)\n","    center_x = (x1+x2)/2\n","    center_y = (y1+y2)/2\n","    width = x2 - x1\n","    height =  y2 - y1\n","\n","    center_x = center_x / img_width\n","    center_y = center_y / img_height\n","    width = width / img_width\n","    height = height / img_height\n","\n","    return class_id, round(center_x, 7), round(center_y, 7), round(width, 7), round(height, 7)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"MGtaykZ5SybS","executionInfo":{"status":"ok","timestamp":1632741119004,"user_tz":-540,"elapsed":3227,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}}},"source":["import shutil\n","def make_yoloy_anno_files(df, target_image_dir, target_labels_dir):\n","    #df를 이용해서 한줄한줄 반복하면서 xml_to_txt함수를 실행\n","    for index, row in df.iterrows():\n","        object_name = row['class_name']\n","        xml_label_path = row['anno_filepath']\n","        src_image_path = row['img_filepath']\n","        target_label_path = target_labels_dir + row['img_name'] + '.txt'\n","        shutil.copy(src_image_path, target_image_dir)\n","        xml_to_txt(xml_label_path, target_label_path, object_name)\n","\n","make_yoloy_anno_files(train_df, '/content/ox_pet/images/train/', '/content/ox_pet/labels/train/')\n","make_yoloy_anno_files(val_df, '/content/ox_pet/images/val/', '/content/ox_pet/labels/val/')"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wTFfFGDrWrGs","executionInfo":{"status":"ok","timestamp":1632741130686,"user_tz":-540,"elapsed":821,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"f30e5f47-d7cb-41f4-84e4-4303cef12315"},"source":["!wget -O /content/ox_pet/ox_pet.yaml https://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/ox_pet.yaml"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-09-27 11:13:23--  https://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/ox_pet.yaml\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 754 [text/plain]\n","Saving to: ‘/content/ox_pet/ox_pet.yaml’\n","\n","\r          /content/   0%[                    ]       0  --.-KB/s               \r/content/ox_pet/ox_ 100%[===================>]     754  --.-KB/s    in 0s      \n","\n","2021-09-27 11:13:23 (33.1 MB/s) - ‘/content/ox_pet/ox_pet.yaml’ saved [754/754]\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rMji593rgOwe","executionInfo":{"status":"ok","timestamp":1632741863281,"user_tz":-540,"elapsed":990,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"5306b1ab-5b21-4c94-e727-fbd2eddbfe61"},"source":["!ln -s /content/drive/My\\ Drive/ /mydrive\n","!ls /mydrive\n","!mkdir \"/mydrive/ultra_workdir\""],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["ln: failed to create symbolic link '/mydrive/My Drive': File exists\n"," 텐서플로로배우는딥러닝  'My Drive'\t\t\t        ultra_workdir\n","'2020년 공부.zip'\t  object-detection-and-tracking.ipynb   Untitled0.ipynb\n","'Colab Notebooks'\t  pet\t\t\t\t        공모전.zip\n","'Computer Vision'\t  test.csv\t\t\t        공부파일.zip\n"," MOS.zip\t\t  tf_idf.ipynb\n","mkdir: cannot create directory ‘/mydrive/ultra_workdir’: File exists\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLt_Z4bXX4M3","outputId":"ce5558c0-eb3e-4954-ef8d-98cfc93b02d1"},"source":["!cd /content/yolov3; python train.py --img 640 --batch 8 --epochs 10 --data /content/ox_pet/ox_pet.yaml --weights yolov3.pt --project /mydrive/ultra_workdir \\\n","                                     --name pet --exist-ok "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n","YOLOv3 🚀 v9.5.0-13-g1be3170 torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n","\n","Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=False, cfg='', data='/content/ox_pet/ox_pet.yaml', device='', entity=None, epochs=10, evolve=False, exist_ok=True, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='pet', noautoanchor=False, nosave=False, notest=False, project='/mydrive/ultra_workdir', quad=False, rect=False, resume=False, save_dir='/mydrive/ultra_workdir/pet', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=8, upload_dataset=False, weights='yolov3.pt', workers=8, world_size=1)\n","\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir /mydrive/ultra_workdir', view at http://localhost:6006/\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Don't visualize my results'\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 3e8m2td2.\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n","Overriding model.yaml nc=80 with nc=37\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n","  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n"," 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n"," 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n"," 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n"," 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n"," 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n"," 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n"," 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n"," 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n"," 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n"," 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n"," 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n"," 28      [27, 22, 15]  1    226170  models.yolo.Detect                      [37, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n","Model Summary: 333 layers, 61717594 parameters, 61717594 gradients, 155.7 GFLOPS\n","\n","Transferred 434/440 items from yolov3.pt\n","Scaled weight_decay = 0.0005\n","Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/ox_pet/labels/train.cache' images and labels... 3303 found, 0 missing, 0 empty, 0 corrupted: 100% 3303/3303 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/ox_pet/labels/val.cache' images and labels... 368 found, 0 missing, 0 empty, 0 corrupted: 100% 368/368 [00:00<?, ?it/s]\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","Plotting labels... \n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.90, Best Possible Recall (BPR) = 1.0000\n","Image sizes 640 train, 640 test\n","Using 2 dataloader workers\n","Logging results to /mydrive/ultra_workdir/pet\n","Starting training for 10 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       0/9      7.3G    0.0717    0.0286   0.05865     0.159        22       640:   0% 0/413 [00:11<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:730: UserWarning: The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\n","  \"The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\"\n","       0/9     9.66G    0.1011   0.02653   0.08678    0.2144        19       640:   4% 16/413 [01:01<13:54,  2.10s/it]Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       0/9     9.66G    0.0781     0.021   0.08668    0.1858        15       640:  23% 95/413 [03:41<10:44,  2.03s/it]Corrupt JPEG data: premature end of data segment\n","       0/9     9.66G   0.07785   0.02096   0.08675    0.1856        17       640:  23% 96/413 [03:43<10:38,  2.01s/it]Corrupt JPEG data: premature end of data segment\n","       0/9     9.66G   0.06814   0.01896   0.08593     0.173        15       640:  36% 149/413 [05:30<08:52,  2.02s/it]Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       0/9     9.66G   0.06623   0.01858   0.08606    0.1709        21       640:  40% 164/413 [06:00<08:19,  2.01s/it]Corrupt JPEG data: premature end of data segment\n","       0/9     9.66G   0.06398   0.01799   0.08587    0.1678        24       640:  45% 187/413 [06:47<07:36,  2.02s/it]Corrupt JPEG data: premature end of data segment\n","Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       0/9     9.66G   0.06016   0.01727   0.08545    0.1629        13       640:  54% 222/413 [07:57<06:24,  2.01s/it]Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       0/9     9.66G   0.05958   0.01714   0.08558    0.1623        17       640:  55% 229/413 [08:11<06:12,  2.02s/it]Corrupt JPEG data: premature end of data segment\n","       0/9     9.66G   0.05922   0.01698   0.08564    0.1618        17       640:  57% 236/413 [08:25<05:55,  2.01s/it]Corrupt JPEG data: premature end of data segment\n","       0/9     9.66G   0.05565   0.01624   0.08496    0.1568        21       640:  68% 282/413 [09:58<04:22,  2.01s/it]Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       0/9     9.66G   0.05395   0.01584   0.08486    0.1546        17       640:  75% 309/413 [10:52<03:27,  2.00s/it]Corrupt JPEG data: premature end of data segment\n","       0/9     9.66G   0.05234   0.01543   0.08481    0.1526        17       640:  82% 340/413 [11:54<02:26,  2.01s/it]Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       0/9     9.64G   0.04946   0.01464   0.08461    0.1487        19       640: 100% 413/413 [14:28<00:00,  2.10s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 23/23 [00:57<00:00,  2.49s/it]\n","                 all         368         368      0.0289       0.477      0.0551      0.0326\n","Images sizes do not match. This will causes images to be display incorrectly in the UI.\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       1/9      9.5G   0.03379  0.009725   0.08247     0.126        24       640:  18% 76/413 [02:32<11:15,  2.00s/it]Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       1/9      9.5G   0.03318  0.009649   0.08223    0.1251        20       640:  23% 97/413 [03:14<10:32,  2.00s/it]Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       1/9      9.5G   0.03321  0.009636   0.08261    0.1255        16       640:  29% 121/413 [04:02<09:44,  2.00s/it]Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       1/9      9.5G   0.03268  0.009411   0.08195     0.124        18       640:  40% 164/413 [05:28<08:20,  2.01s/it]Corrupt JPEG data: premature end of data segment\n","       1/9      9.5G   0.03294  0.009394   0.08206    0.1244        19       640:  43% 176/413 [05:52<07:56,  2.01s/it]Corrupt JPEG data: premature end of data segment\n","       1/9      9.5G   0.03281  0.009324   0.08185     0.124        18       640:  45% 187/413 [06:14<07:31,  2.00s/it]Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       1/9      9.5G   0.03266  0.009267   0.08203     0.124        18       640:  51% 209/413 [06:58<06:48,  2.00s/it]Corrupt JPEG data: premature end of data segment\n","       1/9      9.5G   0.03261  0.009249   0.08199    0.1238        17       640:  52% 213/413 [07:06<06:42,  2.01s/it]Corrupt JPEG data: premature end of data segment\n","       1/9      9.5G   0.03277  0.009213   0.08194    0.1239        21       640:  56% 231/413 [07:42<06:02,  1.99s/it]Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       1/9      9.5G   0.03251  0.008989   0.08176    0.1233        18       640:  76% 314/413 [10:28<03:18,  2.00s/it]Corrupt JPEG data: premature end of data segment\n","       1/9      9.5G   0.03241  0.008959   0.08173    0.1231        21       640:  79% 325/413 [10:50<02:55,  2.00s/it]Corrupt JPEG data: premature end of data segment\n","       1/9      9.5G   0.03249  0.008768   0.08194    0.1232        18       640:  89% 366/413 [12:12<01:34,  2.00s/it]Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       1/9      9.5G   0.03254  0.008628   0.08189    0.1231        20       640: 100% 413/413 [13:46<00:00,  2.00s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 23/23 [00:22<00:00,  1.03it/s]\n","                 all         368         368      0.0455       0.294      0.0693      0.0502\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       2/9      9.5G   0.03183  0.007135   0.08134    0.1203        17       640:  40% 164/413 [05:28<08:17,  2.00s/it]Corrupt JPEG data: premature end of data segment\n","       2/9      9.5G   0.03211  0.007125   0.08123    0.1205        14       640:  45% 187/413 [06:14<07:30,  1.99s/it]Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       2/9      9.5G   0.03202  0.007017   0.08084    0.1199        14       640:  77% 317/413 [10:34<03:11,  2.00s/it]Corrupt JPEG data: premature end of data segment\n","       2/9      9.5G   0.03199  0.006902   0.08006     0.119        13       640: 100% 413/413 [13:45<00:00,  2.00s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 23/23 [00:22<00:00,  1.03it/s]\n","                 all         368         368      0.0367       0.457      0.0703      0.0392\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       3/9      9.5G   0.03335  0.005904   0.07959    0.1188        18       640:   3% 13/413 [00:26<13:20,  2.00s/it]Corrupt JPEG data: premature end of data segment\n","       3/9      9.5G   0.03193  0.006044   0.07827    0.1162        18       640:  35% 144/413 [04:47<08:55,  1.99s/it]Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       3/9      9.5G   0.03165  0.006119   0.07834    0.1161        17       640:  40% 164/413 [05:27<08:16,  1.99s/it]Corrupt JPEG data: premature end of data segment\n","       3/9      9.5G   0.03161  0.006122    0.0784    0.1161        19       640:  40% 167/413 [05:33<08:08,  1.99s/it]Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       3/9      9.5G   0.03143  0.006091    0.0783    0.1158        18       640:  45% 187/413 [06:13<07:33,  2.01s/it]Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       3/9      9.5G   0.03125  0.006095   0.07816    0.1155        18       640:  47% 196/413 [06:31<07:13,  2.00s/it]Corrupt JPEG data: premature end of data segment\n","       3/9      9.5G   0.03113   0.00608   0.07778     0.115        13       640:  74% 307/413 [10:12<03:31,  2.00s/it]Corrupt JPEG data: premature end of data segment\n","       3/9      9.5G   0.03098  0.006135   0.07797    0.1151        18       640:  85% 353/413 [11:44<01:59,  2.00s/it]Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       3/9      9.5G   0.03084  0.006104   0.07784    0.1148        11       640: 100% 413/413 [13:43<00:00,  1.99s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 23/23 [00:22<00:00,  1.03it/s]\n","                 all         368         368      0.0808       0.522       0.129      0.0987\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       4/9      9.5G   0.02851  0.005717    0.0789    0.1131        11       640:   2% 8/413 [00:16<13:37,  2.02s/it]Corrupt JPEG data: premature end of data segment\n","       4/9      9.5G   0.03133  0.005601   0.07559    0.1125        15       640:  25% 102/413 [03:24<10:24,  2.01s/it]Corrupt JPEG data: premature end of data segment\n","       4/9      9.5G   0.03116  0.005618   0.07574    0.1125        19       640:  37% 151/413 [05:01<08:43,  2.00s/it]Corrupt JPEG data: premature end of data segment\n","       4/9      9.5G   0.03104  0.005605   0.07545    0.1121        14       640:  40% 164/413 [05:27<08:16,  1.99s/it]Corrupt JPEG data: premature end of data segment\n","       4/9      9.5G   0.03091  0.005635   0.07541     0.112        18       640:  45% 187/413 [06:13<07:31,  2.00s/it]Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n","       4/9      9.5G   0.03066  0.005702   0.07555    0.1119        16       640:  53% 218/413 [07:15<06:28,  1.99s/it]"]}]},{"cell_type":"code","metadata":{"id":"ZeeoUrMJe9VD"},"source":["!pip install wandb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jnYNB-Z2hZwT","executionInfo":{"status":"ok","timestamp":1632742017376,"user_tz":-540,"elapsed":4,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"2b3d1a56-9250-4b07-c442-4b17d7107a46"},"source":["import torch\n","from IPython.display import Image, clear_output  # to display images\n","\n","clear_output()\n","print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Setup complete. Using torch 1.9.0+cu102 (Tesla K80)\n"]}]},{"cell_type":"code","metadata":{"id":"WGmokKoMAg-n"},"source":[""],"execution_count":null,"outputs":[]}]}