{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"yolov3_train_coco.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM863pT/Dtv4FxJCe7RwAIC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k4jzIhSitEOD","executionInfo":{"status":"ok","timestamp":1631783787954,"user_tz":-540,"elapsed":3450,"user":{"displayName":"Î∞ïÏ¢ÖÎëê","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"df3248c9-c201-4c24-b49b-1d5ff4bd0306"},"source":["!git clone https://github.com/ultralytics/yolov3\n","%cd yolov3\n","!pip install -qr requirements.txt"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'yolov3' already exists and is not an empty directory.\n","/content/yolov3\n"]}]},{"cell_type":"code","metadata":{"id":"-j8F8gbU5kiL","executionInfo":{"status":"ok","timestamp":1631783906555,"user_tz":-540,"elapsed":6727,"user":{"displayName":"Î∞ïÏ¢ÖÎëê","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}}},"source":["!pip install -qr requirements.txt"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rzd8rBcZ5AA3","executionInfo":{"status":"ok","timestamp":1631783980867,"user_tz":-540,"elapsed":68875,"user":{"displayName":"Î∞ïÏ¢ÖÎëê","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"b616a134-7506-4f86-f486-c002b7d5e9d2"},"source":["!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ‚úÖ\n","YOLOv3 üöÄ v9.5.0-13-g1be3170 torch 1.9.0+cu102 CPU\n","\n","Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=False, cfg='', data='./data/coco128.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp2', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, weights='yolov3.pt', workers=8, world_size=1)\n","\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n","\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n","  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n"," 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n"," 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n"," 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n"," 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n"," 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n"," 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n"," 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n"," 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n"," 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n"," 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n"," 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n"," 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n","Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.4 GFLOPS\n","\n","Transferred 440/440 items from yolov3.pt\n","Scaled weight_decay = 0.0005\n","Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]Plotting labels... \n","\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:02<?, ?it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:02<?, ?it/s]\n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.26, Best Possible Recall (BPR) = 0.9946\n","Image sizes 640 train, 640 test\n","Using 2 dataloader workers\n","Logging results to runs/train/exp2\n","Starting training for 3 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","  0% 0/8 [00:00<?, ?it/s]^C\n"]}]},{"cell_type":"code","metadata":{"id":"wP4V2eqk5HXt"},"source":[""],"execution_count":null,"outputs":[]}]}