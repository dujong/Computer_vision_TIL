{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"yolov5_train_bccd.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1xU2j_X_unXPW_XgxZ_hr5DZYZCrQjoCJ","authorship_tag":"ABX9TyMAwxvGl7XtxnKa7IyKkU5X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QIAqYzdbInw3","executionInfo":{"status":"ok","timestamp":1632878117534,"user_tz":-540,"elapsed":6508,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"7dcdfe8c-546f-40b2-aefe-d8ac353ace41"},"source":["!git clone https://github.com/ultralytics/yolov5\n","!cd yolov5;pip install -qr requirements.txt"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 9322, done.\u001b[K\n","remote: Counting objects: 100% (73/73), done.\u001b[K\n","remote: Compressing objects: 100% (73/73), done.\u001b[K\n","remote: Total 9322 (delta 35), reused 14 (delta 0), pack-reused 9249\u001b[K\n","Receiving objects: 100% (9322/9322), 9.89 MiB | 24.81 MiB/s, done.\n","Resolving deltas: 100% (6457/6457), done.\n","\u001b[K     |████████████████████████████████| 636 kB 5.4 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0fWqpm5mKHti","executionInfo":{"status":"ok","timestamp":1632878133979,"user_tz":-540,"elapsed":1965,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"00b50e4b-56c9-40fd-b650-9a2f362afc23"},"source":["!git clone https://github.com/Shenggan/BCCD_Dataset.git\n","!git clone https://github.com/yukkyo/voc2coco.git"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'BCCD_Dataset'...\n","remote: Enumerating objects: 800, done.\u001b[K\n","remote: Total 800 (delta 0), reused 0 (delta 0), pack-reused 800\u001b[K\n","Receiving objects: 100% (800/800), 7.39 MiB | 21.31 MiB/s, done.\n","Resolving deltas: 100% (378/378), done.\n","Cloning into 'voc2coco'...\n","remote: Enumerating objects: 423, done.\u001b[K\n","remote: Counting objects: 100% (14/14), done.\u001b[K\n","remote: Compressing objects: 100% (11/11), done.\u001b[K\n","remote: Total 423 (delta 3), reused 8 (delta 3), pack-reused 409\u001b[K\n","Receiving objects: 100% (423/423), 214.64 KiB | 2.13 MiB/s, done.\n","Resolving deltas: 100% (379/379), done.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWopQH_hKN0J","executionInfo":{"status":"ok","timestamp":1632878137943,"user_tz":-540,"elapsed":236,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"81f4af01-f760-4e4d-cc71-d5dc54fd0a3f"},"source":["import os\n"," \n","with open('/content/BCCD_Dataset/BCCD/labels.txt', \"w\") as f:\n","    f.write(\"WBC\\n\")\n","    f.write(\"RBC\\n\")\n","    f.write(\"Platelets\\n\")\n","\n","!cat /content/BCCD_Dataset/BCCD/labels.txt"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["WBC\n","RBC\n","Platelets\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ko_hqzP6KfDL","executionInfo":{"status":"ok","timestamp":1632878143470,"user_tz":-540,"elapsed":830,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"3624703c-51b0-44c0-b67e-048234e46a5f"},"source":["%cd voc2coco\n","!python voc2coco.py --ann_dir /content/BCCD_Dataset/BCCD/Annotations \\\n","    --ann_ids /content/BCCD_Dataset/BCCD/ImageSets/Main/train.txt \\\n","    --labels /content/BCCD_Dataset/BCCD/labels.txt \\\n","    --output /content/BCCD_Dataset/BCCD/train.json \\\n","    --ext xml\n","\n","!python voc2coco.py --ann_dir /content/BCCD_Dataset/BCCD/Annotations \\\n","    --ann_ids /content/BCCD_Dataset/BCCD/ImageSets/Main/val.txt \\\n","    --labels /content/BCCD_Dataset/BCCD/labels.txt \\\n","    --output /content/BCCD_Dataset/BCCD/val.json \\\n","    --ext xml\n","\n","!python voc2coco.py --ann_dir /content/BCCD_Dataset/BCCD/Annotations \\\n","    --ann_ids /content/BCCD_Dataset/BCCD/ImageSets/Main/test.txt \\\n","    --labels /content/BCCD_Dataset/BCCD/labels.txt \\\n","    --output /content/BCCD_Dataset/BCCD/test.json \\\n","    --ext xml"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/voc2coco\n","Start converting !\n","100% 205/205 [00:00<00:00, 4235.15it/s]\n","Start converting !\n","100% 87/87 [00:00<00:00, 3452.79it/s]\n","Start converting !\n","100% 72/72 [00:00<00:00, 3450.17it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dMJr_3PrLMZb","executionInfo":{"status":"ok","timestamp":1632878145633,"user_tz":-540,"elapsed":234,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"c616915d-da0c-4067-b9e0-8b21b96e53e3"},"source":["%cd /content"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","metadata":{"id":"lUAsYLc5LazA","executionInfo":{"status":"ok","timestamp":1632878147301,"user_tz":-540,"elapsed":622,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}}},"source":["!mkdir /content/bccd;\n","!cd /content/bccd; mkdir images; mkdir labels;\n","!cd /content/bccd/images; mkdir train; mkdir val; mkdir test;\n","!cd /content/bccd/labels; mkdir train; mkdir val; mkdir test;"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"O1nbLQs0LbTQ","executionInfo":{"status":"ok","timestamp":1632878149130,"user_tz":-540,"elapsed":239,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}}},"source":["# https://github.com/alexmihalyk23/COCO2YOLO.git\n","import json\n","import os\n","import shutil\n","\n","class COCO2YOLO:\n","  # 소스 이미지 디렉토리와 Json annotation 파일, 타겟 이미지 디렉토리, 타겟 annotation 디렉토리를 생성자로 입력 받음. \n","  def __init__(self, src_img_dir, json_file, tgt_img_dir, tgt_anno_dir):\n","    self.json_file = json_file\n","    self.src_img_dir = src_img_dir\n","    self.tgt_img_dir = tgt_img_dir\n","    self.tgt_anno_dir = tgt_anno_dir\n","    # json 파일과 타겟 디렉토리가 존재하는지 확인하고, 디렉토리의 경우는 없으면 생성. \n","    self._check_file_and_dir(json_file, tgt_img_dir, tgt_anno_dir)\n","    # json 파일을 메모리로 로딩. \n","    self.labels = json.load(open(json_file, 'r', encoding='utf-8'))\n","    # category id와 이름을 매핑하지만, 실제 class id는 이를 적용하지 않고 별도 적용. \n","    self.coco_id_name_map = self._categories()\n","    self.coco_name_list = list(self.coco_id_name_map.values())\n","    print(\"total images\", len(self.labels['images']))\n","    print(\"total categories\", len(self.labels['categories']))\n","    print(\"total labels\", len(self.labels['annotations']))\n","  \n","  # json 파일과 타겟 디렉토리가 존재하는지 확인하고, 디렉토리의 경우는 없으면 생성. \n","  def _check_file_and_dir(self, file_path, tgt_img_dir, tgt_anno_dir):\n","    if not os.path.exists(file_path):\n","        raise ValueError(\"file not found\")\n","    if not os.path.exists(tgt_img_dir):\n","        os.makedirs(tgt_img_dir)\n","    if not os.path.exists(tgt_anno_dir):\n","        os.makedirs(tgt_anno_dir)\n","\n","  # category id와 이름을 매핑하지만, 추후에 class 명만 활용. \n","  def _categories(self):\n","    categories = {}\n","    for cls in self.labels['categories']:\n","        categories[cls['id']] = cls['name']\n","    return categories\n","  \n","  # annotation에서 모든 image의 파일명(절대 경로 아님)과 width, height 정보 저장. \n","  def _load_images_info(self):\n","    images_info = {}\n","    for image in self.labels['images']:\n","        id = image['id']\n","        file_name = image['file_name']\n","        if file_name.find('\\\\') > -1:\n","            file_name = file_name[file_name.index('\\\\')+1:]\n","        w = image['width']\n","        h = image['height']\n","  \n","        images_info[id] = (file_name, w, h)\n","\n","    return images_info\n","\n","  # ms-coco의 bbox annotation은 yolo format으로 변환. 좌상단 x, y좌표, width, height 기반을 정규화된 center x,y 와 width, height로 변환. \n","  def _bbox_2_yolo(self, bbox, img_w, img_h):\n","    # ms-coco는 좌상단 x, y좌표, width, height\n","    x, y, w, h = bbox[0], bbox[1], bbox[2], bbox[3]\n","    # center x좌표는 좌상단 x좌표에서 width의 절반을 더함. center y좌표는 좌상단 y좌표에서 height의 절반을 더함.  \n","    centerx = bbox[0] + w / 2\n","    centery = bbox[1] + h / 2\n","    # centerx, centery, width, height를 이미지의 width/height로 정규화. \n","    dw = 1 / img_w\n","    dh = 1 / img_h\n","    centerx *= dw\n","    w *= dw\n","    centery *= dh\n","    h *= dh\n","    return centerx, centery, w, h\n","  \n","  # image와 annotation 정보를 기반으로 image명과 yolo annotation 정보 가공. \n","  # 개별 image당 하나의 annotation 정보를 가지도록 변환. \n","  def _convert_anno(self, images_info):\n","    anno_dict = dict()\n","    for anno in self.labels['annotations']:\n","      bbox = anno['bbox']\n","      image_id = anno['image_id']\n","      category_id = anno['category_id']\n","\n","      image_info = images_info.get(image_id)\n","      image_name = image_info[0]\n","      img_w = image_info[1]\n","      img_h = image_info[2]\n","      yolo_box = self._bbox_2_yolo(bbox, img_w, img_h)\n","\n","      anno_info = (image_name, category_id, yolo_box)\n","      anno_infos = anno_dict.get(image_id)\n","      if not anno_infos:\n","        anno_dict[image_id] = [anno_info]\n","      else:\n","        anno_infos.append(anno_info)\n","        anno_dict[image_id] = anno_infos\n","    return anno_dict\n","\n","  # class 명을 파일로 저장하는 로직. 사용하지 않음. \n","  def save_classes(self):\n","    sorted_classes = list(map(lambda x: x['name'], sorted(self.labels['categories'], key=lambda x: x['id'])))\n","    print('coco names', sorted_classes)\n","    with open('coco.names', 'w', encoding='utf-8') as f:\n","      for cls in sorted_classes:\n","          f.write(cls + '\\n')\n","    f.close()\n","  # _convert_anno(images_info)로 만들어진 anno 정보를 개별 yolo anno txt 파일로 생성하는 로직. \n","  # coco2yolo()에서 anno_dict = self._convert_anno(images_info)로 만들어진 anno_dict를 _save_txt()에 입력하여 파일 생성\n","  def _save_txt(self, anno_dict):\n","    # 개별 image별로 소스 image는 타겟이미지 디렉토리로 복사하고, 개별 annotation을 타겟 anno 디렉토리로 생성. \n","    for k, v in anno_dict.items():\n","      # 소스와 타겟 파일의 절대 경로 생성. \n","      src_img_filename = os.path.join(self.src_img_dir, v[0][0])\n","      tgt_anno_filename = os.path.join(self.tgt_anno_dir,v[0][0].split(\".\")[0] + \".txt\")\n","      #print('source image filename:', src_img_filename, 'target anno filename:', tgt_anno_filename)\n","      # 이미지 파일의 경우 타겟 디렉토리로 단순 복사. \n","      shutil.copy(src_img_filename, self.tgt_img_dir)\n","      # 타겟 annotation 출력 파일명으로 classid, bbox 좌표를 object 별로 생성. \n","      with open(tgt_anno_filename, 'w', encoding='utf-8') as f:\n","        #print(k, v)\n","        # 여러개의 object 별로 classid와 bbox 좌표를 생성. \n","        for obj in v:\n","          cat_name = self.coco_id_name_map.get(obj[1])\n","          # category_id는 class 명에 따라 0부터 순차적으로 부여. \n","          category_id = self.coco_name_list.index(cat_name)\n","          #print('cat_name:', cat_name, 'category_id:', category_id)\n","          box = ['{:.6f}'.format(x) for x in obj[2]]\n","          box = ' '.join(box)\n","          line = str(category_id) + ' ' + box\n","          f.write(line + '\\n')\n","\n","  # ms-coco를 yolo format으로 변환. \n","  def coco2yolo(self):\n","    print(\"loading image info...\")\n","    images_info = self._load_images_info()\n","    print(\"loading done, total images\", len(images_info))\n","\n","    print(\"start converting...\")\n","    anno_dict = self._convert_anno(images_info)\n","    print(\"converting done, total labels\", len(anno_dict))\n","\n","    print(\"saving txt file...\")\n","    self._save_txt(anno_dict)\n","    print(\"saving done\")\n","\n","  "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cvq0ttdtRaaq","executionInfo":{"status":"ok","timestamp":1632878158104,"user_tz":-540,"elapsed":240,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"71d74491-79ab-4216-8747-2a815172afc8"},"source":["# train 용 yolo 데이터 세트 생성. \n","train_yolo_converter = COCO2YOLO(src_img_dir='/content/BCCD_Dataset/BCCD/JPEGImages', json_file='/content/BCCD_Dataset/BCCD/train.json',\n","                                 tgt_img_dir='/content/bccd/images/train', tgt_anno_dir='/content/bccd/labels/train')\n","train_yolo_converter.coco2yolo()\n","\n","# val 용 yolo 데이터 세트 생성. \n","val_yolo_converter = COCO2YOLO(src_img_dir='/content/BCCD_Dataset/BCCD/JPEGImages', json_file='/content/BCCD_Dataset/BCCD/val.json',\n","                                 tgt_img_dir='/content/bccd/images/val', tgt_anno_dir='/content/bccd/labels/val')\n","val_yolo_converter.coco2yolo()\n","\n","# test 용 yolo 데이터 세트 생성. \n","test_yolo_converter = COCO2YOLO(src_img_dir='/content/BCCD_Dataset/BCCD/JPEGImages', json_file='/content/BCCD_Dataset/BCCD/test.json',\n","                                 tgt_img_dir='/content/bccd/images/test', tgt_anno_dir='/content/bccd/labels/test')\n","test_yolo_converter.coco2yolo()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["total images 205\n","total categories 3\n","total labels 2805\n","loading image info...\n","loading done, total images 205\n","start converting...\n","converting done, total labels 205\n","saving txt file...\n","saving done\n","total images 87\n","total categories 3\n","total labels 1138\n","loading image info...\n","loading done, total images 87\n","start converting...\n","converting done, total labels 87\n","saving txt file...\n","saving done\n","total images 72\n","total categories 3\n","total labels 945\n","loading image info...\n","loading done, total images 72\n","start converting...\n","converting done, total labels 72\n","saving txt file...\n","saving done\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rcdVnk_0Rghn","executionInfo":{"status":"ok","timestamp":1632878161167,"user_tz":-540,"elapsed":328,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"053c2ba3-fcdf-49ba-d77a-6fd3d6228003"},"source":["!wget -O /content/bccd/bccd.yaml https://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/bccd.yaml"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-09-29 01:17:12--  https://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/bccd.yaml\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 184 [text/plain]\n","Saving to: ‘/content/bccd/bccd.yaml’\n","\n","\r/content/bccd/bccd.   0%[                    ]       0  --.-KB/s               \r/content/bccd/bccd. 100%[===================>]     184  --.-KB/s    in 0s      \n","\n","2021-09-29 01:17:12 (9.89 MB/s) - ‘/content/bccd/bccd.yaml’ saved [184/184]\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D6XzavK_R3T5","executionInfo":{"status":"ok","timestamp":1632878163948,"user_tz":-540,"elapsed":609,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"7982296f-9521-49c3-fd43-c37ab01767f5"},"source":["# soft link로 Google Drive Directory 연결. \n","!ln -s /content/drive/My\\ Drive/ /mydrive\n","!ls /mydrive\n","# Google Drive 밑에 Directory 생성. 이미 생성 되어 있을 시 오류 발생. \n","!mkdir \"/mydrive/ultra_workdir\""],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":[" 텐서플로로배우는딥러닝  'My Drive'\t\t\t        ultra_workdir\n","'2020년 공부.zip'\t  object-detection-and-tracking.ipynb   Untitled0.ipynb\n","'Colab Notebooks'\t  pet\t\t\t\t        공모전.zip\n","'Computer Vision'\t  test.csv\t\t\t        공부파일.zip\n"," MOS.zip\t\t  tf_idf.ipynb\n","mkdir: cannot create directory ‘/mydrive/ultra_workdir’: File exists\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EfMqpdVrR6wY","executionInfo":{"status":"ok","timestamp":1632832744529,"user_tz":-540,"elapsed":2270563,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"b20b329b-c6b4-4b76-f358-a4065d684df2"},"source":["###  10번 미만 epoch는 좋은 성능이 안나옴. 최소 30번 이상 epoch 적용. large 모델 적용 시 batch size가 8보다 클 경우 colab에서 memory 부족 발생.\n","### 혈소판의 경우 상대적으로 mAP:0.5~0.95 Detection 성능이 좋지 못함. 백혈구 만큼 학습데이터가 적은것도 이유지만, Object 사이즈가 상대적으로 작음.   \n","!cd /content/yolov5; python train.py --img 640 --batch 8 --epochs 30 --data /content/bccd/bccd.yaml --weights yolov5l.pt \\\n","                                     --project=/mydrive/ultra_workdir --name bccd --exist-ok "],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l.pt, cfg=, data=/content/bccd/bccd.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=30, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, entity=None, project=/mydrive/ultra_workdir, name=bccd, exist_ok=True, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=100\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v5.0-472-gc1bed60 torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /mydrive/ultra_workdir', view at http://localhost:6006/\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5l.pt to yolov5l.pt...\n","100% 90.2M/90.2M [00:04<00:00, 20.5MB/s]\n","\n","Overriding model.yaml nc=80 with nc=3\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      7040  models.common.Focus                     [3, 64, 3]                    \n","  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n","  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  4                -1  9   1611264  models.common.C3                        [256, 256, 9]                 \n","  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n","  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n","  8                -1  1   2624512  models.common.SPP                       [1024, 1024, [5, 9, 13]]      \n","  9                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n"," 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n"," 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n"," 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n"," 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n"," 24      [17, 20, 23]  1     43080  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n","Model Summary: 499 layers, 46642120 parameters, 46642120 gradients, 114.3 GFLOPs\n","\n","Transferred 644/650 items from yolov5l.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 107 weight, 110 weight (no decay), 110 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/bccd/labels/train' images and labels...205 found, 0 missing, 0 empty, 0 corrupted: 100% 205/205 [00:00<00:00, 1463.74it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/bccd/labels/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/bccd/labels/val' images and labels...87 found, 0 missing, 0 empty, 0 corrupted: 100% 87/87 [00:00<00:00, 776.44it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/bccd/labels/val.cache\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","Plotting labels... \n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.76, Best Possible Recall (BPR) = 0.9996\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/mydrive/ultra_workdir/bccd\u001b[0m\n","Starting training for 30 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      0/29     5.25G    0.1118    0.1549   0.03825       136       640: 100% 26/26 [01:08<00:00,  2.63s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:08<00:00,  1.34s/it]\n","                 all         87       1138     0.0473      0.112     0.0293    0.00541\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      1/29     5.61G   0.09712    0.1771   0.03414       153       640: 100% 26/26 [01:04<00:00,  2.48s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:08<00:00,  1.40s/it]\n","                 all         87       1138      0.067      0.167     0.0612      0.012\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      2/29     5.61G    0.0847    0.1893   0.02934        75       640: 100% 26/26 [01:04<00:00,  2.47s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:08<00:00,  1.49s/it]\n","                 all         87       1138      0.461      0.215      0.105     0.0255\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      3/29     5.61G   0.07746    0.1736   0.02492        84       640: 100% 26/26 [01:03<00:00,  2.43s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:08<00:00,  1.47s/it]\n","                 all         87       1138      0.835      0.164      0.165     0.0532\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      4/29     5.61G    0.0671    0.1709   0.02041        85       640: 100% 26/26 [01:03<00:00,  2.44s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:08<00:00,  1.39s/it]\n","                 all         87       1138       0.86      0.214       0.21     0.0933\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      5/29     5.61G   0.05827    0.1563   0.01765       117       640: 100% 26/26 [01:03<00:00,  2.44s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:07<00:00,  1.28s/it]\n","                 all         87       1138      0.363      0.381      0.323      0.161\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      6/29     5.61G   0.05285    0.1627   0.01573       127       640: 100% 26/26 [01:03<00:00,  2.44s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:07<00:00,  1.25s/it]\n","                 all         87       1138       0.37      0.488      0.421      0.221\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      7/29     5.61G   0.04781    0.1548   0.01469        94       640: 100% 26/26 [01:03<00:00,  2.44s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:07<00:00,  1.20s/it]\n","                 all         87       1138      0.656      0.621      0.639       0.31\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      8/29     5.61G   0.05285    0.1636   0.01279       122       640: 100% 26/26 [01:03<00:00,  2.43s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:07<00:00,  1.20s/it]\n","                 all         87       1138      0.403      0.674      0.513      0.164\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      9/29     5.61G   0.05311    0.1481   0.01252       105       640: 100% 26/26 [01:03<00:00,  2.43s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:07<00:00,  1.19s/it]\n","                 all         87       1138       0.43      0.777      0.613      0.269\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     10/29     5.61G   0.04942     0.158   0.01144       143       640: 100% 26/26 [01:03<00:00,  2.42s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:07<00:00,  1.18s/it]\n","                 all         87       1138      0.521      0.855      0.649      0.336\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     11/29     5.61G   0.04745    0.1488   0.01041       140       640: 100% 26/26 [01:03<00:00,  2.43s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:07<00:00,  1.17s/it]\n","                 all         87       1138      0.643      0.768      0.742      0.395\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     12/29     5.61G    0.0474    0.1502  0.009625       159       640: 100% 26/26 [01:03<00:00,  2.43s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:07<00:00,  1.17s/it]\n","                 all         87       1138      0.554      0.775      0.684      0.363\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     13/29     5.61G   0.04823     0.158  0.008493       103       640: 100% 26/26 [01:03<00:00,  2.42s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:07<00:00,  1.17s/it]\n","                 all         87       1138      0.396      0.721       0.52      0.161\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     14/29     5.61G   0.05578    0.1522  0.007829       178       640: 100% 26/26 [01:03<00:00,  2.42s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:06<00:00,  1.16s/it]\n","                 all         87       1138      0.553      0.735      0.696      0.383\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     15/29     5.61G   0.05117    0.1491  0.006821       154       640: 100% 26/26 [01:02<00:00,  2.42s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:06<00:00,  1.16s/it]\n","                 all         87       1138      0.563      0.801      0.739      0.421\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     16/29     5.61G   0.04395    0.1362  0.006121       119       640: 100% 26/26 [01:03<00:00,  2.43s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:06<00:00,  1.16s/it]\n","                 all         87       1138      0.442      0.752      0.654      0.306\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     17/29     5.61G   0.04531    0.1551  0.005515       168       640: 100% 26/26 [01:02<00:00,  2.42s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:06<00:00,  1.16s/it]\n","                 all         87       1138      0.591       0.74        0.7      0.344\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     18/29     5.61G   0.04296    0.1435  0.004957       111       640: 100% 26/26 [01:02<00:00,  2.42s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:06<00:00,  1.16s/it]\n","                 all         87       1138       0.67      0.765      0.741      0.465\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     19/29     5.61G    0.0471    0.1343  0.004787       131       640: 100% 26/26 [01:03<00:00,  2.42s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:06<00:00,  1.16s/it]\n","                 all         87       1138      0.465      0.811      0.654      0.377\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     20/29     5.61G   0.04506    0.1359  0.004388       123       640: 100% 26/26 [01:02<00:00,  2.41s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:06<00:00,  1.16s/it]\n","                 all         87       1138      0.566      0.812      0.711      0.366\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     21/29     5.61G   0.04248    0.1452  0.004234       116       640: 100% 26/26 [01:02<00:00,  2.41s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:06<00:00,  1.16s/it]\n","                 all         87       1138      0.695      0.783      0.743      0.401\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     22/29     5.61G   0.03973    0.1378  0.004393        99       640: 100% 26/26 [01:02<00:00,  2.42s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:06<00:00,  1.16s/it]\n","                 all         87       1138      0.824      0.851      0.856      0.535\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     23/29     5.61G   0.03937    0.1318  0.003726       132       640: 100% 26/26 [01:02<00:00,  2.42s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:06<00:00,  1.16s/it]\n","                 all         87       1138      0.845       0.87      0.874      0.507\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     24/29     5.61G   0.03864    0.1412  0.003654       146       640: 100% 26/26 [01:02<00:00,  2.42s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:06<00:00,  1.15s/it]\n","                 all         87       1138      0.744      0.869      0.851      0.487\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     25/29     5.61G   0.03922    0.1397  0.003615       134       640: 100% 26/26 [01:02<00:00,  2.42s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:06<00:00,  1.15s/it]\n","                 all         87       1138       0.73      0.859      0.824      0.514\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     26/29     5.61G   0.03657    0.1312  0.003366        96       640: 100% 26/26 [01:02<00:00,  2.41s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:06<00:00,  1.16s/it]\n","                 all         87       1138      0.699      0.806      0.786      0.443\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     27/29     5.61G   0.04049    0.1292  0.003293        80       640: 100% 26/26 [01:02<00:00,  2.41s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:06<00:00,  1.16s/it]\n","                 all         87       1138       0.69       0.85      0.847       0.48\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     28/29     5.61G   0.03699    0.1305   0.00322        97       640: 100% 26/26 [01:02<00:00,  2.41s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:06<00:00,  1.15s/it]\n","                 all         87       1138      0.737       0.84      0.883       0.54\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     29/29     5.61G   0.03419    0.1249  0.003108       104       640: 100% 26/26 [01:02<00:00,  2.42s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:06<00:00,  1.15s/it]\n","                 all         87       1138      0.752      0.779      0.831      0.462\n","\n","30 epochs completed in 0.615 hours.\n","Optimizer stripped from /mydrive/ultra_workdir/bccd/weights/last.pt, 93.7MB\n","Optimizer stripped from /mydrive/ultra_workdir/bccd/weights/best.pt, 93.7MB\n","\n","Validating /mydrive/ultra_workdir/bccd/weights/best.pt...\n","Fusing layers... \n","Model Summary: 392 layers, 46611336 parameters, 0 gradients, 114.1 GFLOPs\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:10<00:00,  1.77s/it]\n","                 all         87       1138      0.736      0.839      0.882      0.541\n","                 WBC         87         87      0.588          1      0.962      0.727\n","                 RBC         87        968       0.85      0.747      0.871      0.539\n","           Platelets         87         83      0.771      0.771      0.815      0.356\n","Results saved to \u001b[1m/mydrive/ultra_workdir/bccd\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"khXWj3eMR8TA","executionInfo":{"status":"ok","timestamp":1632878195582,"user_tz":-540,"elapsed":19913,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"aa61d1c4-a186-44ff-8447-8238dcbd2d03"},"source":["# image 파일 inference \n","!cd /content/yolov5;python detect.py --source /content/bccd/images/test/BloodImage_00011.jpg \\\n","                            --weights /mydrive/ultra_workdir/bccd/weights/best.pt --conf 0.2 \\\n","                            --project=/content/data/output --name=run_image --exist-ok --line-thickness 2"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/mydrive/ultra_workdir/bccd/weights/best.pt'], source=/content/bccd/images/test/BloodImage_00011.jpg, imgsz=[640, 640], conf_thres=0.2, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/content/data/output, name=run_image, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False\n","YOLOv5 🚀 v5.0-481-g9988059 torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n","\n","Fusing layers... \n","Model Summary: 392 layers, 46611336 parameters, 0 gradients, 114.1 GFLOPs\n","image 1/1 /content/bccd/images/test/BloodImage_00011.jpg: 480x640 1 WBC, 20 RBCs, 1 Platelets, Done. (0.103s)\n","Speed: 0.7ms pre-process, 103.3ms inference, 34.4ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1m/content/data/output/run_image\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9cL1pLIjSCYP","executionInfo":{"status":"ok","timestamp":1632878285246,"user_tz":-540,"elapsed":21578,"user":{"displayName":"박종두","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17239507866944241595"}},"outputId":"e989756c-2ad9-4959-9c5f-27680ac9dbdc"},"source":["!cd /content/yolov5; python val.py --weights /mydrive/ultra_workdir/bccd/weights/best.pt  --data /content/bccd/bccd.yaml \\\n","                           --project /content/data/output --name=test_result --exist-ok --img 640 --iou 0.65\n"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mdata=/content/bccd/bccd.yaml, weights=['/mydrive/ultra_workdir/bccd/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, task=val, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=/content/data/output, name=test_result, exist_ok=True, half=False\n","YOLOv5 🚀 v5.0-481-g9988059 torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n","\n","Fusing layers... \n","Model Summary: 392 layers, 46611336 parameters, 0 gradients, 114.1 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/bccd/labels/val' images and labels...87 found, 0 missing, 0 empty, 0 corrupted: 100% 87/87 [00:00<00:00, 1132.30it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/bccd/labels/val.cache\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:10<00:00,  3.66s/it]\n","                 all         87       1138      0.673      0.829      0.859      0.533\n","                 WBC         87         87      0.495          1      0.955      0.722\n","                 RBC         87        968      0.855      0.732      0.866      0.536\n","           Platelets         87         83      0.669      0.756      0.757      0.339\n","Speed: 0.4ms pre-process, 73.9ms inference, 3.0ms NMS per image at shape (32, 3, 640, 640)\n","Results saved to \u001b[1m/content/data/output/test_result\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"znS_xA60SDmg"},"source":[""],"execution_count":null,"outputs":[]}]}